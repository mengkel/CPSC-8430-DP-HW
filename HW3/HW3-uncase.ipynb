{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0beec3cc-f684-4890-8e88-5dfb8c50223f",
   "metadata": {},
   "source": [
    "Import neccesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "543226ec-0f87-4e93-a214-8f76befd918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as pt\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b923117d-74b1-4e01-9927-cac7e90106e2",
   "metadata": {},
   "source": [
    "Here I will load the \"squad\" dataset first to see the data format before I process the spoken_squad data which is not available on datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8dd302-54f3-40a4-8f82-1ec36f9e3d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/mengkel/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ef723291bc4726bc22359637b95662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08cd8f7d-473f-41be-9d9b-f61e96f47cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70fa340-e0cc-4f5f-803d-970a5074212a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary. \n",
      "\n",
      "Question:  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France? \n",
      "\n",
      "Answer:  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]} \n",
      "\n",
      "Id:  5733be284776f41900661182\n"
     ]
    }
   ],
   "source": [
    "print(\"Context: \", raw_datasets[\"train\"][0][\"context\"],'\\n')\n",
    "print(\"Question: \", raw_datasets[\"train\"][0][\"question\"], '\\n')\n",
    "print(\"Answer: \", raw_datasets[\"train\"][0][\"answers\"], '\\n')\n",
    "print(\"Id: \", raw_datasets[\"train\"][0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac278b8-eb41-4b71-9d38-05c7dc2a707e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a89ea7-bfe0-4614-870e-440b9a72e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_checkpoint = \"bert-base-cased\"\n",
    "model_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b085479d-d15b-4caf-b6b6-a6948c7d9729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41a2042-e4f2-4805-82e8-24617dc16bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] to whom did the virgin mary allegedly appear in 1858 in lourdes france? [SEP] architecturally, the school has a catholic character. atop the main building\\'s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \" venite ad me omnes \". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive ( and in a direct line that connects through 3 statues and the gold dome ), is a simple, modern stone statue of mary. [SEP]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = raw_datasets[\"train\"][0][\"context\"]\n",
    "question = raw_datasets[\"train\"][0][\"question\"]\n",
    "\n",
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca30f5b-1007-496b-8c8a-97b63c5043d0",
   "metadata": {},
   "source": [
    "Download the spoken_train and spoken_test data from the link provided in the hw slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6936cfc-a79f-4493-acd9-01445fc18f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/mengkel/.cache/huggingface/datasets/json/default-ece21904abacfb66/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1f2aafe86d4a86bb522ea1c816069a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('json', data_files='spoken_train-v1.1.json', field = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d5227f-39f1-4d42-88a1-3ea4452b77af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'paragraphs'],\n",
       "    num_rows: 442\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84cccca-51bf-49de-92cd-c94c283df6ef",
   "metadata": {},
   "source": [
    "Here is the steps to process the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20dbc986-a7fb-40d4-96cb-f273ba72cebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dat_pre):\n",
    "    qid_lst, title_lst, context_lst, question_lst, answer_lst = [], [], [], [], []\n",
    "    DEBUG_RUN = False\n",
    "    for i, dat in enumerate(dat_pre):\n",
    "        if DEBUG_RUN and len(context_lst) > 5000:\n",
    "            break\n",
    "        title = dat['title']\n",
    "        for para in dat['paragraphs']:\n",
    "            context = para['context']\n",
    "            for qa in para['qas']:\n",
    "                question = qa['question']\n",
    "                q_id = qa['id']\n",
    "\n",
    "                answer_text = qa['answers'][0]['text']\n",
    "                answer_start = qa['answers'][0]['answer_start']\n",
    "                assert type(answer_start)==int and answer_start >= 0\n",
    "                #assert context[answer_start:answer_start + len(answer_text)] == answer_text\n",
    "\n",
    "                part_before = context[:answer_start] + ' @@@@@ '\n",
    "                part_after = ' @@@@@ ' + context[answer_start + len(answer_text):]\n",
    "                new_context = part_before + answer_text + part_after\n",
    "\n",
    "                qid_lst.append(q_id)\n",
    "                title_lst.append(title)\n",
    "                context_lst.append(new_context)\n",
    "                question_lst.append(question)\n",
    "                answer_lst.append([answer_text, answer_start])\n",
    "    return qid_lst, title_lst, context_lst, question_lst, answer_lst \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9643b62-2661-4042-98a3-83b21438c781",
   "metadata": {},
   "source": [
    "I firstly did the data processing for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f6b0c7-f662-4752-ba67-33282dc10349",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_data = {\"train\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03be2efb-efa8-4eeb-8841-e3af2201223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_lst, title_lst, context_lst, question_lst, answer_lst = get_data(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9047bba2-2088-4e71-a4f5-4b2bda1f1ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37111\n"
     ]
    }
   ],
   "source": [
    "print(len(qid_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b259d57-942e-4850-9014-7064e756ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(qid_lst)):\n",
    "    prod_data[\"train\"].append({'id': qid_lst[i], 'title': title_lst[i], 'context': context_lst[i], \\\n",
    "    'question': question_lst[i], 'answers': {'text': [answer_lst[i][0]], 'answer_start': [answer_lst[i][1]]}, \"split\": \"train\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3dc2a77-b5b5-4224-9433-8f8ae6231134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is  @@@@@ a copper statue of christ @@@@@  with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary. \n",
      "\n",
      "Question:  What is in front of the Notre Dame Main Building? \n",
      "\n",
      "Answer:  {'text': ['a copper statue of christ'], 'answer_start': [187]} \n",
      "\n",
      "Id:  5733be284776f4190066117f\n"
     ]
    }
   ],
   "source": [
    "print(\"Context: \", prod_data[\"train\"][0][\"context\"],'\\n')\n",
    "print(\"Question: \", prod_data[\"train\"][0][\"question\"], '\\n')\n",
    "print(\"Answer: \", prod_data[\"train\"][0][\"answers\"], '\\n')\n",
    "print(\"Id: \", prod_data[\"train\"][0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aeeeac5-d00f-45b0-b172-b827ba632432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/mengkel/.cache/huggingface/datasets/json/default-983f0672be846a2e/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e5c8bd729148c0a546d14753b2295f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset1 = load_dataset('json', data_files='spoken_test-v1.1_WER54.json', field = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eebf60e6-91f9-4529-abf4-431f46a19364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'paragraphs'],\n",
       "        num_rows: 48\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ded7d15-d4d8-4acf-9709-9236dda40384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'paragraphs'],\n",
       "    num_rows: 48\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72b315cb-fc7f-440b-94eb-0adae83c6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "qid_lst1, title_lst1, context_lst1, question_lst1, answer_lst1 = get_data(dataset1['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4832eb9-604c-44c2-ae70-70943c05ae3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5351\n"
     ]
    }
   ],
   "source": [
    "print(len(qid_lst1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c087c715-a924-4626-8dfc-d62a1049630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_data[\"validation\"]= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae1a9940-6c78-4af8-9019-04b1e8700e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(qid_lst1)):\n",
    "    prod_data[\"validation\"].append({'id': qid_lst1[i], 'title': title_lst1[i], 'context': context_lst1[i], \\\n",
    "    'question': question_lst1[i], 'answers': {'text': [answer_lst1[i][0]], 'answer_start': [answer_lst1[i][1]]}, \"split\": \"validation\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c383045a-68ea-40fd-8fbb-4b18de98b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context:  Two five oh fifty with an american football game to determine the champion of the national football league and f for the twenty fifteen feet then. The american football conferen @@@@@ Denver Broncos @@@@@ hampion denver broncos defeated the national football conference and effie champion carolina panthers twenty four to ten to earn their parents super bowl title. The game was played on february seventh one fifteen and revive the indian san francisco bay area santa clara california. If if with the fiftieth super bowl the league emphasize the golden anniversary with various gulf view the initiative as well as temporarily defending the tradition of naming each super bowl game with roman numeral find her with a game would have been known as super bowl felt that the logo of prominently featured the arabic numerals fifty. \n",
      "\n",
      "Question:  Which NFL team represented the AFC at Super Bowl 50? \n",
      "\n",
      "Answer:  {'text': ['Denver Broncos'], 'answer_start': [177]} \n",
      "\n",
      "Id:  56be4db0acb8001400a502ec\n"
     ]
    }
   ],
   "source": [
    "print(\"Context: \", prod_data[\"validation\"][0][\"context\"],'\\n')\n",
    "print(\"Question: \", prod_data[\"validation\"][0][\"question\"], '\\n')\n",
    "print(\"Answer: \", prod_data[\"validation\"][0][\"answers\"], '\\n')\n",
    "print(\"Id: \", prod_data[\"validation\"][0][\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b1d0007-bda4-452d-9a0d-574c4760ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f4190066117f',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is  @@@@@ a copper statue of christ @@@@@  with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary.',\n",
       " 'question': 'What is in front of the Notre Dame Main Building?',\n",
       " 'answers': {'text': ['a copper statue of christ'], 'answer_start': [187]},\n",
       " 'split': 'train'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_data[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb9d709c-ddd0-4c5c-8f1d-5183ae71a596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '56be4db0acb8001400a502ec',\n",
       " 'title': 'Super_Bowl_50',\n",
       " 'context': 'Two five oh fifty with an american football game to determine the champion of the national football league and f for the twenty fifteen feet then. The american football conferen @@@@@ Denver Broncos @@@@@ hampion denver broncos defeated the national football conference and effie champion carolina panthers twenty four to ten to earn their parents super bowl title. The game was played on february seventh one fifteen and revive the indian san francisco bay area santa clara california. If if with the fiftieth super bowl the league emphasize the golden anniversary with various gulf view the initiative as well as temporarily defending the tradition of naming each super bowl game with roman numeral find her with a game would have been known as super bowl felt that the logo of prominently featured the arabic numerals fifty.',\n",
       " 'question': 'Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'answers': {'text': ['Denver Broncos'], 'answer_start': [177]},\n",
       " 'split': 'validation'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_data[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30e6c702-396d-45c8-80a1-3e7096afc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74c53ba-a648-431c-840c-5ba2e390d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_data.json\", \"w\") as json_file:\n",
    "    # write the dictionary to the file\n",
    "    json.dump(prod_data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec6107e3-2198-426a-8aa9-738925b2a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/mengkel/.cache/huggingface/datasets/json/default-4db658885caa2bb1/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e1e881c4784e4ab64a9dd56efd2e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa7424f434a4a7a9effd550a6308fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/mengkel/.cache/huggingface/datasets/json/default-4db658885caa2bb1/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a7b466ee3443b6801d8fd852fe0c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = load_dataset('json', data_files='my_data.json', field = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8042eda-a5d5-4683-b394-8c4104796095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'split'],\n",
       "        num_rows: 37111\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b64286e-03f7-4f6c-b04c-331d2c62dfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /home/mengkel/.cache/huggingface/datasets/json/default-c9383a109aecedbd/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efb7768a21cb454f84cbca4f740cb7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4073f1f660e4b5fbf524d3accb59313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/mengkel/.cache/huggingface/datasets/json/default-c9383a109aecedbd/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7edfa6541a42948e0b89b0176c0816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = load_dataset('json', data_files='my_data.json', field = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08160840-d2a3-4785-99cc-171d901108cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers', 'split'],\n",
       "        num_rows: 5351\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56bcd1ff-bd0d-4264-ae06-d5de33d55cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = prod_data[\"train\"][0][\"context\"]\n",
    "question = prod_data[\"validation\"][0][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b2b301d-13e0-485b-abee-5a78793bf77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] which nfl team represented the afc at super bowl 50? [SEP] architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is @ @ @ @ @ a copper statue of christ @ @ @ @ @ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary. [SEP]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(question, context)\n",
    "tokenizer.decode(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "48d1029e-096d-4226-9e87-773f24038c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] which nfl team represented the afc at super bowl 50? [SEP] architecturally the school has a catholic character. atop the main building school dome is the golden statue of the virgin mary. immediately in front of the main building in facing it is @ @ @ @ @ a copper statue of christ @ @ @ @ @ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto [SEP]\n",
      "[CLS] which nfl team represented the afc at super bowl 50? [SEP] @ @ @ @ a copper statue of christ @ @ @ @ @ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen [SEP]\n",
      "[CLS] which nfl team represented the afc at super bowl 50? [SEP] basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen fifty eight. at the end of the main drive and in a direct line that connects through three statues in the gold dome is as simple modern stone statue of mary. [SEP]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    ")\n",
    "\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "381860f6-4c84-47ad-99c0-8a92c489369b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c7c5a8ae-70cb-4453-aeac-de531ccdbb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([84, 48, 0], [85, 49, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = train_data[\"train\"][2:6][\"answers\"]\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n",
    "    answer = answers[sample_idx]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # Find the start and end of the context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "        idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "        idx += 1\n",
    "    context_end = idx - 1\n",
    "\n",
    "    # If the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # Otherwise it's the start and end token positions\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "010e8203-9ad6-446b-805b-d216b664fbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: twice, labels give: the basilica\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "start = start_positions[idx]\n",
    "end = end_positions[idx]\n",
    "labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5af71b1-d1db-48bf-852b-0a62943cbea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: twice, decoded example: [CLS] which nfl team represented the afc at super bowl 50? [SEP] @ @ @ @ a copper statue of christ @ @ @ @ @ with arms appraised with the legend and the bad meow names. next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto im mary in place of prayer and reflection. it is a replica of the grotto at lourdes france where the virgin mary reputedly appeared to st bernadette still burning eighteen [SEP]\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "decoded_example = tokenizer.decode(inputs[\"input_ids\"][idx])\n",
    "print(f\"Theoretical answer: {answer}, decoded example: {decoded_example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afffd6cf-9656-4b77-8d0e-f9e6eb506154",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a098cb0-0717-4597-b61c-d9bcc79992d1",
   "metadata": {},
   "source": [
    "some examples in this dataset have extra spaces at the beginning and the end that don’t add anything, so we removed those extra spaces.\n",
    "\n",
    "To apply this function to the whole training set, we use the Dataset.map() method with the batched=True flag. It’s necessary here as we are changing the length of the dataset (since one example can give several training features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b49fc65-f713-4cf0-a27b-7e1d79798b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_data['train'].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=train_data['train'].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf90f995-d582-4334-beaf-a95af5fa72ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37111, 37361)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8243008a-3661-4fd1-b2e1-7d728225cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6a2c920-7dab-4a9e-892d-6025c1ac5ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5351, 5444)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = test_data[\"train\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=test_data[\"train\"].column_names,\n",
    ")\n",
    "len(test_data[\"train\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772883c-d250-407f-ae39-81c7bfa90641",
   "metadata": {},
   "source": [
    "Fine-tuning the model with the Trainer API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06930718-9da0-46b6-8439-66cf0b783bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_eval_set = test_data[\"train\"].select(range(100))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=test_data[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0847be2e-2b2b-4b27-b388-f1146581e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e988b4b9-8879-4044-b010-e8d464fb915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de60d4e8-e15c-4dbd-838c-325f11dd4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e963a6e-607a-451e-9074-a05c9cc8cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in small_eval_set:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a0ac20f-5f1b-4815-84f0-485ee8edba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0b04ce85-a37e-4e82-89ae-c8f7a2bf4978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '56be8e613aeaaa14008c90d1', 'prediction_text': 'revive the indian san francisco bay area santa clara california'}\n",
      "{'id': '56be8e613aeaaa14008c90d1', 'answers': {'answer_start': [487], 'text': ['\"golden anniversary\"']}}\n"
     ]
    }
   ],
   "source": [
    "print(predicted_answers[5])\n",
    "print(theoretical_answers[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "962813a8-417e-4ee7-b89a-a73c17eabaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f92e75fb-9e43-4731-8818-93b1d73ad16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1862b8a-aa51-4196-8753-4d9d95a4218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80516380-dbc3-419c-a7b4-ae93841e1f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 39.0, 'f1': 50.56825396825397}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ec02a2c-1d99-4e7e-b0d8-2b06a6095e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "981eb8cf-254a-4576-82c7-bf9b25d3d6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49ace82769d4a20ab210a974882de70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 39.0, 'f1': 50.56825396825397}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(start_logits, end_logits, eval_set, small_eval_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b82b7-35f5-42e3-81ce-44cf5fe07f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ec1805-572d-419a-a498-33c4d3763313",
   "metadata": {},
   "source": [
    "Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8570f982-17f4-4039-ae5a-fd61fdd3a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8e800bd-5ab0-4176-bdb6-fcf987ba9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c41688b-c51a-4786-9a9e-460d012fe9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: ipywidgets in ./.conda/envs/skln/lib/python3.8/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipywidgets) (6.9.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipywidgets) (8.3.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.2.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: nest-asyncio in ./.conda/envs/skln/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: pickleshare in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (61.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: stack-data in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in ./.conda/envs/skln/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=22.3 in ./.conda/envs/skln/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: entrypoints in ./.conda/envs/skln/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in ./.conda/envs/skln/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/envs/skln/lib/python3.8/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.conda/envs/skln/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.conda/envs/skln/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.conda/envs/skln/lib/python3.8/site-packages (from python-dateutil>=2.8.2->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: asttokens in ./.conda/envs/skln/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in ./.conda/envs/skln/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in ./.conda/envs/skln/lib/python3.8/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1377ad2d-b6f2-41a9-a327-2ebc7d940432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6098c963f42471ebc44b0319db7d23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "396318c8-d408-4233-aed0-72045d220d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-squad\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f8c1245-1aaa-45c1-aaee-b25553ee70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15bf9e5d-acb9-459f-b5e5-9bde7cdeb1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: git-lfs in ./.conda/envs/skln/lib/python3.8/site-packages (1.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b0213-0047-43a5-a767-09c47703d3ee",
   "metadata": {},
   "source": [
    "The easy wayy to train it is to use the Trainer from transformers package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f36287a9-2a30-4ed6-8bbb-fed9049e01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mengkel/.conda/envs/skln/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14013' max='14013' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14013/14013 21:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.837900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.321700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.261400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.237600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.150100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.099900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.041800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.040700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14013, training_loss=0.14140971237099043, metrics={'train_runtime': 1290.7806, 'train_samples_per_second': 86.834, 'train_steps_per_second': 10.856, 'total_flos': 2.1965193288930816e+16, 'train_loss': 0.14140971237099043, 'epoch': 3.0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6455330e-f518-4476-8ead-9e94f6fd0601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf8fa6ba71146258b3df703dc66b641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 5.064473930106522, 'f1': 59.210471019732445}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions, _, _ = trainer.predict(validation_dataset)\n",
    "# start_logits, end_logits = predictions\n",
    "# compute_metrics(start_logits, end_logits, validation_dataset, prod_data[\"validation\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
